{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3484, 30, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = [\n",
    "    'come',\n",
    "    'away',\n",
    "    'spin',\n",
    "    'hello'\n",
    "]\n",
    "\n",
    "data = np.concatenate([\n",
    "    np.load('/home/seojin/Documents/gesture-recognition/dataset/seq_away_1725372496.npy'),\n",
    "    np.load('/home/seojin/Documents/gesture-recognition/dataset/seq_come_1725372496.npy'),\n",
    "    np.load('/home/seojin/Documents/gesture-recognition/dataset/seq_hello_1725372496.npy'),\n",
    "    np.load('/home/seojin/Documents/gesture-recognition/dataset/seq_spin_1725372496.npy')\n",
    "], axis=0)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3484, 30, 99)\n",
      "(3484,)\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:, :, :-1]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3484, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_data = to_categorical(labels, num_classes=len(actions))\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3135, 30, 99) (3135, 4)\n",
      "(349, 30, 99) (349, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1, random_state=2021)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 64)                41984     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44196 (172.64 KB)\n",
      "Trainable params: 44196 (172.64 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=x_train.shape[1:4]),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(actions), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 19.3913 - acc: 0.6124\n",
      "Epoch 1: val_acc improved from -inf to 0.83668, saving model to models/model.h5\n",
      "98/98 [==============================] - 11s 53ms/step - loss: 19.3913 - acc: 0.6124 - val_loss: 1.4860 - val_acc: 0.8367 - lr: 0.0010\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seojin/.local/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - ETA: 0s - loss: 0.5117 - acc: 0.8973\n",
      "Epoch 2: val_acc improved from 0.83668 to 0.90831, saving model to models/model.h5\n",
      "98/98 [==============================] - 5s 49ms/step - loss: 0.5117 - acc: 0.8973 - val_loss: 0.4823 - val_acc: 0.9083 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.1941 - acc: 0.9499\n",
      "Epoch 3: val_acc improved from 0.90831 to 0.95989, saving model to models/model.h5\n",
      "98/98 [==============================] - 4s 42ms/step - loss: 0.1941 - acc: 0.9499 - val_loss: 0.0847 - val_acc: 0.9599 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.3741 - acc: 0.9238\n",
      "Epoch 4: val_acc did not improve from 0.95989\n",
      "98/98 [==============================] - 5s 46ms/step - loss: 0.3741 - acc: 0.9238 - val_loss: 0.4496 - val_acc: 0.8968 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.2712 - acc: 0.9518\n",
      "Epoch 5: val_acc improved from 0.95989 to 0.97135, saving model to models/model.h5\n",
      "98/98 [==============================] - 5s 46ms/step - loss: 0.2712 - acc: 0.9518 - val_loss: 0.0959 - val_acc: 0.9713 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.0968 - acc: 0.9762\n",
      "Epoch 6: val_acc improved from 0.97135 to 0.99140, saving model to models/model.h5\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 0.0959 - acc: 0.9764 - val_loss: 0.0489 - val_acc: 0.9914 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9890\n",
      "Epoch 7: val_acc did not improve from 0.99140\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.0413 - acc: 0.9892 - val_loss: 0.0121 - val_acc: 0.9914 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9897\n",
      "Epoch 8: val_acc improved from 0.99140 to 0.99427, saving model to models/model.h5\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 0.0352 - acc: 0.9898 - val_loss: 0.0088 - val_acc: 0.9943 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9958\n",
      "Epoch 9: val_acc improved from 0.99427 to 0.99713, saving model to models/model.h5\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 0.0176 - acc: 0.9959 - val_loss: 0.0061 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9980\n",
      "Epoch 10: val_acc did not improve from 0.99713\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.0060 - acc: 0.9981 - val_loss: 0.0075 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.0018 - acc: 0.9997\n",
      "Epoch 11: val_acc did not improve from 0.99713\n",
      "98/98 [==============================] - 3s 27ms/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.0142 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9997\n",
      "Epoch 12: val_acc did not improve from 0.99713\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0059 - val_acc: 0.9943 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9987\n",
      "Epoch 13: val_acc did not improve from 0.99713\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.0032 - acc: 0.9987 - val_loss: 0.0054 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 4.3353e-04 - acc: 1.0000\n",
      "Epoch 14: val_acc improved from 0.99713 to 1.00000, saving model to models/model.h5\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 4.2934e-04 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 3.0873e-04 - acc: 1.0000\n",
      "Epoch 15: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 3.0873e-04 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.4448e-04 - acc: 1.0000\n",
      "Epoch 16: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 2.4278e-04 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 1.9143e-04 - acc: 1.0000\n",
      "Epoch 17: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 1.9087e-04 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.6962e-04 - acc: 1.0000\n",
      "Epoch 18: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 1.6800e-04 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 1.4081e-04 - acc: 1.0000\n",
      "Epoch 19: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 1.3806e-04 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.2315e-04 - acc: 1.0000\n",
      "Epoch 20: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 1.2527e-04 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 9.5132e-05 - acc: 1.0000\n",
      "Epoch 21: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 9.5132e-05 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 7.8261e-05 - acc: 1.0000\n",
      "Epoch 22: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 7.8261e-05 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 7.1239e-05 - acc: 1.0000\n",
      "Epoch 23: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 37ms/step - loss: 7.1239e-05 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 6.9678e-05 - acc: 1.0000\n",
      "Epoch 24: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 25ms/step - loss: 6.9678e-05 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 5.2211e-05 - acc: 1.0000\n",
      "Epoch 25: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 31ms/step - loss: 5.2120e-05 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 4.4771e-05 - acc: 1.0000\n",
      "Epoch 26: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 34ms/step - loss: 4.4398e-05 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 4.0010e-05 - acc: 1.0000\n",
      "Epoch 27: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 3.9706e-05 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.4904e-05 - acc: 1.0000\n",
      "Epoch 28: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 3.4594e-05 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.1062e-05 - acc: 1.0000\n",
      "Epoch 29: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 3.0782e-05 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "95/98 [============================>.] - ETA: 0s - loss: 2.8635e-05 - acc: 1.0000\n",
      "Epoch 30: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 2.7923e-05 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.5667e-05 - acc: 1.0000\n",
      "Epoch 31: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.5494e-05 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.3456e-05 - acc: 1.0000\n",
      "Epoch 32: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.3456e-05 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.1486e-05 - acc: 1.0000\n",
      "Epoch 33: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 2.1486e-05 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 1.9532e-05 - acc: 1.0000\n",
      "Epoch 34: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 1.9532e-05 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 1.8461e-05 - acc: 1.0000\n",
      "Epoch 35: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 1.8132e-05 - acc: 1.0000 - val_loss: 0.0140 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.7227e-05 - acc: 1.0000\n",
      "Epoch 36: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 1.7058e-05 - acc: 1.0000 - val_loss: 0.0144 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 1.5808e-05 - acc: 1.0000\n",
      "Epoch 37: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 1.5546e-05 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.4713e-05 - acc: 1.0000\n",
      "Epoch 38: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 1.4635e-05 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 1.3839e-05 - acc: 1.0000\n",
      "Epoch 39: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 1.3601e-05 - acc: 1.0000 - val_loss: 0.0145 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 1.2639e-05 - acc: 1.0000\n",
      "Epoch 40: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 1.2639e-05 - acc: 1.0000 - val_loss: 0.0148 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.1815e-05 - acc: 1.0000\n",
      "Epoch 41: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 1.1698e-05 - acc: 1.0000 - val_loss: 0.0147 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.1083e-05 - acc: 1.0000\n",
      "Epoch 42: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 1.1006e-05 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.0338e-05 - acc: 1.0000\n",
      "Epoch 43: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 1.0254e-05 - acc: 1.0000 - val_loss: 0.0156 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 9.7173e-06 - acc: 1.0000\n",
      "Epoch 44: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 9.6256e-06 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 9.0871e-06 - acc: 1.0000\n",
      "Epoch 45: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 9.0871e-06 - acc: 1.0000 - val_loss: 0.0164 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 8.4779e-06 - acc: 1.0000\n",
      "Epoch 46: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 8.4779e-06 - acc: 1.0000 - val_loss: 0.0153 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 7.8135e-06 - acc: 1.0000\n",
      "Epoch 47: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 8.0382e-06 - acc: 1.0000 - val_loss: 0.0163 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 8.2954e-06 - acc: 1.0000\n",
      "Epoch 48: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 50ms/step - loss: 8.2954e-06 - acc: 1.0000 - val_loss: 0.0153 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 9.6261e-06 - acc: 1.0000\n",
      "Epoch 49: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 52ms/step - loss: 9.6261e-06 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 8.4469e-06 - acc: 1.0000\n",
      "Epoch 50: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 50ms/step - loss: 8.4469e-06 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 7.6832e-06 - acc: 1.0000\n",
      "Epoch 51: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 54ms/step - loss: 7.6832e-06 - acc: 1.0000 - val_loss: 0.0164 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 6.7031e-06 - acc: 1.0000\n",
      "Epoch 52: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 6s 57ms/step - loss: 6.6673e-06 - acc: 1.0000 - val_loss: 0.0165 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 6.1977e-06 - acc: 1.0000\n",
      "Epoch 53: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 46ms/step - loss: 6.1977e-06 - acc: 1.0000 - val_loss: 0.0163 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 5.9145e-06 - acc: 1.0000\n",
      "Epoch 54: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 54ms/step - loss: 5.9145e-06 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 5.4727e-06 - acc: 1.0000\n",
      "Epoch 55: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 55ms/step - loss: 5.4727e-06 - acc: 1.0000 - val_loss: 0.0169 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 5.2092e-06 - acc: 1.0000\n",
      "Epoch 56: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 6s 63ms/step - loss: 5.2092e-06 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 4.8508e-06 - acc: 1.0000\n",
      "Epoch 57: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 7s 67ms/step - loss: 4.8508e-06 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 4.5954e-06 - acc: 1.0000\n",
      "Epoch 58: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 47ms/step - loss: 4.5954e-06 - acc: 1.0000 - val_loss: 0.0173 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 4.3672e-06 - acc: 1.0000\n",
      "Epoch 59: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 39ms/step - loss: 4.3422e-06 - acc: 1.0000 - val_loss: 0.0177 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 4.1300e-06 - acc: 1.0000\n",
      "Epoch 60: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 31ms/step - loss: 4.0965e-06 - acc: 1.0000 - val_loss: 0.0176 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 3.8818e-06 - acc: 1.0000\n",
      "Epoch 61: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 3.8818e-06 - acc: 1.0000 - val_loss: 0.0170 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.7233e-06 - acc: 1.0000\n",
      "Epoch 62: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 3.6914e-06 - acc: 1.0000 - val_loss: 0.0182 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 3.3792e-06 - acc: 1.0000\n",
      "Epoch 63: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 32ms/step - loss: 3.4997e-06 - acc: 1.0000 - val_loss: 0.0180 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 3.3104e-06 - acc: 1.0000\n",
      "Epoch 64: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "98/98 [==============================] - 3s 26ms/step - loss: 3.3104e-06 - acc: 1.0000 - val_loss: 0.0182 - val_acc: 0.9971 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 3.1510e-06 - acc: 1.0000\n",
      "Epoch 65: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 3.1510e-06 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 66/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 3.1354e-06 - acc: 1.0000\n",
      "Epoch 66: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 3.0728e-06 - acc: 1.0000 - val_loss: 0.0182 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 67/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 3.0001e-06 - acc: 1.0000\n",
      "Epoch 67: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 54ms/step - loss: 3.0001e-06 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 68/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.9148e-06 - acc: 1.0000\n",
      "Epoch 68: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 7s 70ms/step - loss: 2.9148e-06 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 69/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.8720e-06 - acc: 1.0000\n",
      "Epoch 69: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 6s 66ms/step - loss: 2.8454e-06 - acc: 1.0000 - val_loss: 0.0187 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 70/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.7532e-06 - acc: 1.0000\n",
      "Epoch 70: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 42ms/step - loss: 2.7532e-06 - acc: 1.0000 - val_loss: 0.0189 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 71/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.6797e-06 - acc: 1.0000\n",
      "Epoch 71: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 6s 65ms/step - loss: 2.6797e-06 - acc: 1.0000 - val_loss: 0.0187 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 72/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.6006e-06 - acc: 1.0000\n",
      "Epoch 72: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 7s 72ms/step - loss: 2.6006e-06 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 73/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.5283e-06 - acc: 1.0000\n",
      "Epoch 73: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 44ms/step - loss: 2.5283e-06 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 74/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.4418e-06 - acc: 1.0000\n",
      "Epoch 74: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 45ms/step - loss: 2.4418e-06 - acc: 1.0000 - val_loss: 0.0190 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 75/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.3887e-06 - acc: 1.0000\n",
      "Epoch 75: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 44ms/step - loss: 2.3682e-06 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 76/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.2911e-06 - acc: 1.0000\n",
      "Epoch 76: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 6s 58ms/step - loss: 2.2911e-06 - acc: 1.0000 - val_loss: 0.0192 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 77/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.2400e-06 - acc: 1.0000\n",
      "Epoch 77: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 56ms/step - loss: 2.2179e-06 - acc: 1.0000 - val_loss: 0.0196 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 78/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.1573e-06 - acc: 1.0000\n",
      "Epoch 78: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 38ms/step - loss: 2.1573e-06 - acc: 1.0000 - val_loss: 0.0201 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 79/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.1112e-06 - acc: 1.0000\n",
      "Epoch 79: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 51ms/step - loss: 2.0906e-06 - acc: 1.0000 - val_loss: 0.0200 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 80/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.0064e-06 - acc: 1.0000\n",
      "Epoch 80: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 49ms/step - loss: 2.0064e-06 - acc: 1.0000 - val_loss: 0.0198 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 81/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 1.9411e-06 - acc: 1.0000\n",
      "Epoch 81: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 36ms/step - loss: 1.9411e-06 - acc: 1.0000 - val_loss: 0.0201 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 82/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 1.8743e-06 - acc: 1.0000\n",
      "Epoch 82: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 44ms/step - loss: 1.8743e-06 - acc: 1.0000 - val_loss: 0.0202 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 83/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 1.8005e-06 - acc: 1.0000\n",
      "Epoch 83: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 45ms/step - loss: 1.8005e-06 - acc: 1.0000 - val_loss: 0.0202 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 84/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 1.7369e-06 - acc: 1.0000\n",
      "Epoch 84: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 39ms/step - loss: 1.7369e-06 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 85/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 1.6713e-06 - acc: 1.0000\n",
      "Epoch 85: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 38ms/step - loss: 1.6713e-06 - acc: 1.0000 - val_loss: 0.0205 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 86/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.6008e-06 - acc: 1.0000\n",
      "Epoch 86: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 31ms/step - loss: 1.6128e-06 - acc: 1.0000 - val_loss: 0.0211 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 87/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 1.5495e-06 - acc: 1.0000\n",
      "Epoch 87: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 37ms/step - loss: 1.5495e-06 - acc: 1.0000 - val_loss: 0.0207 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 88/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.4868e-06 - acc: 1.0000\n",
      "Epoch 88: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 35ms/step - loss: 1.4958e-06 - acc: 1.0000 - val_loss: 0.0211 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 89/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 1.4348e-06 - acc: 1.0000\n",
      "Epoch 89: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 50ms/step - loss: 1.4348e-06 - acc: 1.0000 - val_loss: 0.0204 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 90/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 1.4024e-06 - acc: 1.0000\n",
      "Epoch 90: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 41ms/step - loss: 1.3766e-06 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 91/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 1.3244e-06 - acc: 1.0000\n",
      "Epoch 91: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 48ms/step - loss: 1.3244e-06 - acc: 1.0000 - val_loss: 0.0209 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 92/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 1.2648e-06 - acc: 1.0000\n",
      "Epoch 92: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 36ms/step - loss: 1.2648e-06 - acc: 1.0000 - val_loss: 0.0212 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 93/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.2328e-06 - acc: 1.0000\n",
      "Epoch 93: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 42ms/step - loss: 1.2207e-06 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 94/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.1755e-06 - acc: 1.0000\n",
      "Epoch 94: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 39ms/step - loss: 1.1647e-06 - acc: 1.0000 - val_loss: 0.0218 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 95/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 1.1126e-06 - acc: 1.0000\n",
      "Epoch 95: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 38ms/step - loss: 1.1126e-06 - acc: 1.0000 - val_loss: 0.0218 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 96/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 1.0723e-06 - acc: 1.0000\n",
      "Epoch 96: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 34ms/step - loss: 1.0723e-06 - acc: 1.0000 - val_loss: 0.0216 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 97/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 1.0272e-06 - acc: 1.0000\n",
      "Epoch 97: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 39ms/step - loss: 1.0272e-06 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 98/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 9.8238e-07 - acc: 1.0000\n",
      "Epoch 98: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 56ms/step - loss: 9.8238e-07 - acc: 1.0000 - val_loss: 0.0224 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 99/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 9.5141e-07 - acc: 1.0000\n",
      "Epoch 99: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 6s 58ms/step - loss: 9.4200e-07 - acc: 1.0000 - val_loss: 0.0216 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 100/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 9.0155e-07 - acc: 1.0000\n",
      "Epoch 100: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 52ms/step - loss: 9.0155e-07 - acc: 1.0000 - val_loss: 0.0221 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 101/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 8.6672e-07 - acc: 1.0000\n",
      "Epoch 101: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 28ms/step - loss: 8.6672e-07 - acc: 1.0000 - val_loss: 0.0218 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 102/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 8.3263e-07 - acc: 1.0000\n",
      "Epoch 102: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 33ms/step - loss: 8.2847e-07 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 103/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 7.9930e-07 - acc: 1.0000\n",
      "Epoch 103: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 33ms/step - loss: 7.9444e-07 - acc: 1.0000 - val_loss: 0.0223 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 104/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 7.6025e-07 - acc: 1.0000\n",
      "Epoch 104: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 30ms/step - loss: 7.6025e-07 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 105/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 7.2850e-07 - acc: 1.0000\n",
      "Epoch 105: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 29ms/step - loss: 7.2850e-07 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 106/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 6.9607e-07 - acc: 1.0000\n",
      "Epoch 106: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 31ms/step - loss: 6.9607e-07 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 107/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 6.6383e-07 - acc: 1.0000\n",
      "Epoch 107: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 38ms/step - loss: 6.6383e-07 - acc: 1.0000 - val_loss: 0.0229 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 108/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 6.3706e-07 - acc: 1.0000\n",
      "Epoch 108: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 35ms/step - loss: 6.3706e-07 - acc: 1.0000 - val_loss: 0.0226 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 109/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 6.0831e-07 - acc: 1.0000\n",
      "Epoch 109: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 36ms/step - loss: 6.0831e-07 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 110/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 5.8681e-07 - acc: 1.0000\n",
      "Epoch 110: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 41ms/step - loss: 5.8341e-07 - acc: 1.0000 - val_loss: 0.0234 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 111/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 5.5633e-07 - acc: 1.0000\n",
      "Epoch 111: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 7s 69ms/step - loss: 5.5633e-07 - acc: 1.0000 - val_loss: 0.0241 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 112/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 5.3059e-07 - acc: 1.0000\n",
      "Epoch 112: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 45ms/step - loss: 5.3059e-07 - acc: 1.0000 - val_loss: 0.0242 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 113/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 5.0640e-07 - acc: 1.0000\n",
      "Epoch 113: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 43ms/step - loss: 5.0782e-07 - acc: 1.0000 - val_loss: 0.0241 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 114/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 4.8763e-07 - acc: 1.0000\n",
      "Epoch 114: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "98/98 [==============================] - 6s 64ms/step - loss: 4.8763e-07 - acc: 1.0000 - val_loss: 0.0245 - val_acc: 0.9971 - lr: 5.0000e-04\n",
      "Epoch 115/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 4.6382e-07 - acc: 1.0000\n",
      "Epoch 115: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 7s 67ms/step - loss: 4.6382e-07 - acc: 1.0000 - val_loss: 0.0239 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 116/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 4.5302e-07 - acc: 1.0000\n",
      "Epoch 116: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 40ms/step - loss: 4.5302e-07 - acc: 1.0000 - val_loss: 0.0246 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 117/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 4.4280e-07 - acc: 1.0000\n",
      "Epoch 117: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 56ms/step - loss: 4.4280e-07 - acc: 1.0000 - val_loss: 0.0243 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 118/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 4.3462e-07 - acc: 1.0000\n",
      "Epoch 118: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 51ms/step - loss: 4.3032e-07 - acc: 1.0000 - val_loss: 0.0245 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 119/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 4.1850e-07 - acc: 1.0000\n",
      "Epoch 119: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 37ms/step - loss: 4.1850e-07 - acc: 1.0000 - val_loss: 0.0246 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 120/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 4.0797e-07 - acc: 1.0000\n",
      "Epoch 120: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 6s 63ms/step - loss: 4.0797e-07 - acc: 1.0000 - val_loss: 0.0248 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 121/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 4.0033e-07 - acc: 1.0000\n",
      "Epoch 121: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 6s 58ms/step - loss: 3.9637e-07 - acc: 1.0000 - val_loss: 0.0250 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 122/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 3.8595e-07 - acc: 1.0000\n",
      "Epoch 122: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 38ms/step - loss: 3.8595e-07 - acc: 1.0000 - val_loss: 0.0255 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 123/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 3.7470e-07 - acc: 1.0000\n",
      "Epoch 123: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 49ms/step - loss: 3.7470e-07 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 124/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 3.6378e-07 - acc: 1.0000\n",
      "Epoch 124: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 52ms/step - loss: 3.6378e-07 - acc: 1.0000 - val_loss: 0.0253 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 125/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 3.5222e-07 - acc: 1.0000\n",
      "Epoch 125: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 54ms/step - loss: 3.5222e-07 - acc: 1.0000 - val_loss: 0.0250 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 126/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 3.4374e-07 - acc: 1.0000\n",
      "Epoch 126: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 47ms/step - loss: 3.4374e-07 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 127/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.3370e-07 - acc: 1.0000\n",
      "Epoch 127: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 36ms/step - loss: 3.3089e-07 - acc: 1.0000 - val_loss: 0.0254 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 128/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 3.2112e-07 - acc: 1.0000\n",
      "Epoch 128: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 44ms/step - loss: 3.2112e-07 - acc: 1.0000 - val_loss: 0.0255 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 129/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.1465e-07 - acc: 1.0000\n",
      "Epoch 129: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 53ms/step - loss: 3.1169e-07 - acc: 1.0000 - val_loss: 0.0253 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 130/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.0378e-07 - acc: 1.0000\n",
      "Epoch 130: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 47ms/step - loss: 3.0089e-07 - acc: 1.0000 - val_loss: 0.0262 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 131/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.9318e-07 - acc: 1.0000\n",
      "Epoch 131: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 52ms/step - loss: 2.9032e-07 - acc: 1.0000 - val_loss: 0.0261 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 132/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.8001e-07 - acc: 1.0000\n",
      "Epoch 132: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 6s 65ms/step - loss: 2.8001e-07 - acc: 1.0000 - val_loss: 0.0262 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 133/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.7146e-07 - acc: 1.0000\n",
      "Epoch 133: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 52ms/step - loss: 2.7146e-07 - acc: 1.0000 - val_loss: 0.0266 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 134/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.6426e-07 - acc: 1.0000\n",
      "Epoch 134: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 39ms/step - loss: 2.6195e-07 - acc: 1.0000 - val_loss: 0.0262 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 135/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.5283e-07 - acc: 1.0000\n",
      "Epoch 135: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 37ms/step - loss: 2.5283e-07 - acc: 1.0000 - val_loss: 0.0262 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 136/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.4648e-07 - acc: 1.0000\n",
      "Epoch 136: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 36ms/step - loss: 2.4404e-07 - acc: 1.0000 - val_loss: 0.0263 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 137/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.3584e-07 - acc: 1.0000\n",
      "Epoch 137: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 45ms/step - loss: 2.3511e-07 - acc: 1.0000 - val_loss: 0.0272 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 138/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.2889e-07 - acc: 1.0000\n",
      "Epoch 138: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 35ms/step - loss: 2.2663e-07 - acc: 1.0000 - val_loss: 0.0272 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 139/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.1784e-07 - acc: 1.0000\n",
      "Epoch 139: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 33ms/step - loss: 2.1784e-07 - acc: 1.0000 - val_loss: 0.0266 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 140/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.1142e-07 - acc: 1.0000\n",
      "Epoch 140: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 30ms/step - loss: 2.0937e-07 - acc: 1.0000 - val_loss: 0.0275 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 141/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.0184e-07 - acc: 1.0000\n",
      "Epoch 141: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 39ms/step - loss: 2.0184e-07 - acc: 1.0000 - val_loss: 0.0276 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 142/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 1.9416e-07 - acc: 1.0000\n",
      "Epoch 142: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 50ms/step - loss: 1.9416e-07 - acc: 1.0000 - val_loss: 0.0267 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 143/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 1.8628e-07 - acc: 1.0000\n",
      "Epoch 143: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 46ms/step - loss: 1.8628e-07 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 144/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.7927e-07 - acc: 1.0000\n",
      "Epoch 144: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 5s 53ms/step - loss: 1.7853e-07 - acc: 1.0000 - val_loss: 0.0274 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 145/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 1.7199e-07 - acc: 1.0000\n",
      "Epoch 145: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 30ms/step - loss: 1.7199e-07 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 146/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.6672e-07 - acc: 1.0000\n",
      "Epoch 146: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 1.6518e-07 - acc: 1.0000 - val_loss: 0.0276 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 147/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 1.5830e-07 - acc: 1.0000\n",
      "Epoch 147: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 1.5830e-07 - acc: 1.0000 - val_loss: 0.0281 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 148/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.5324e-07 - acc: 1.0000\n",
      "Epoch 148: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 1.5225e-07 - acc: 1.0000 - val_loss: 0.0275 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 149/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 1.4594e-07 - acc: 1.0000\n",
      "Epoch 149: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 32ms/step - loss: 1.4594e-07 - acc: 1.0000 - val_loss: 0.0284 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 150/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.4072e-07 - acc: 1.0000\n",
      "Epoch 150: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 30ms/step - loss: 1.3932e-07 - acc: 1.0000 - val_loss: 0.0280 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 151/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.3388e-07 - acc: 1.0000\n",
      "Epoch 151: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 26ms/step - loss: 1.3362e-07 - acc: 1.0000 - val_loss: 0.0287 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 152/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 1.2818e-07 - acc: 1.0000\n",
      "Epoch 152: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 27ms/step - loss: 1.2818e-07 - acc: 1.0000 - val_loss: 0.0296 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 153/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 1.2309e-07 - acc: 1.0000\n",
      "Epoch 153: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 34ms/step - loss: 1.2259e-07 - acc: 1.0000 - val_loss: 0.0283 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 154/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.1856e-07 - acc: 1.0000\n",
      "Epoch 154: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 28ms/step - loss: 1.1742e-07 - acc: 1.0000 - val_loss: 0.0294 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 155/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 1.1320e-07 - acc: 1.0000\n",
      "Epoch 155: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 30ms/step - loss: 1.1320e-07 - acc: 1.0000 - val_loss: 0.0284 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 156/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.0853e-07 - acc: 1.0000\n",
      "Epoch 156: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 34ms/step - loss: 1.0761e-07 - acc: 1.0000 - val_loss: 0.0284 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 157/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 1.0335e-07 - acc: 1.0000\n",
      "Epoch 157: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 31ms/step - loss: 1.0259e-07 - acc: 1.0000 - val_loss: 0.0293 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 158/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 9.6204e-08 - acc: 1.0000\n",
      "Epoch 158: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 29ms/step - loss: 9.8333e-08 - acc: 1.0000 - val_loss: 0.0289 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 159/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 9.4783e-08 - acc: 1.0000\n",
      "Epoch 159: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 30ms/step - loss: 9.3884e-08 - acc: 1.0000 - val_loss: 0.0286 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 160/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 9.0726e-08 - acc: 1.0000\n",
      "Epoch 160: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 30ms/step - loss: 8.9777e-08 - acc: 1.0000 - val_loss: 0.0287 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 161/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 8.6449e-08 - acc: 1.0000\n",
      "Epoch 161: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 32ms/step - loss: 8.5595e-08 - acc: 1.0000 - val_loss: 0.0295 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 162/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 8.2096e-08 - acc: 1.0000\n",
      "Epoch 162: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 29ms/step - loss: 8.2096e-08 - acc: 1.0000 - val_loss: 0.0304 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 163/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 7.9153e-08 - acc: 1.0000\n",
      "Epoch 163: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 33ms/step - loss: 7.8408e-08 - acc: 1.0000 - val_loss: 0.0299 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 164/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 7.4567e-08 - acc: 1.0000\n",
      "Epoch 164: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 164: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 7.4567e-08 - acc: 1.0000 - val_loss: 0.0310 - val_acc: 0.9971 - lr: 2.5000e-04\n",
      "Epoch 165/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 7.1335e-08 - acc: 1.0000\n",
      "Epoch 165: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 7.1335e-08 - acc: 1.0000 - val_loss: 0.0307 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 166/200\n",
      "95/98 [============================>.] - ETA: 0s - loss: 7.1133e-08 - acc: 1.0000\n",
      "Epoch 166: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 7.0004e-08 - acc: 1.0000 - val_loss: 0.0308 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 167/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 6.7670e-08 - acc: 1.0000\n",
      "Epoch 167: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 6.8103e-08 - acc: 1.0000 - val_loss: 0.0304 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 168/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 6.6506e-08 - acc: 1.0000\n",
      "Epoch 168: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 6.6506e-08 - acc: 1.0000 - val_loss: 0.0306 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 169/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 6.5154e-08 - acc: 1.0000\n",
      "Epoch 169: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 42ms/step - loss: 6.4529e-08 - acc: 1.0000 - val_loss: 0.0310 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 170/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 6.3122e-08 - acc: 1.0000\n",
      "Epoch 170: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 4s 39ms/step - loss: 6.3122e-08 - acc: 1.0000 - val_loss: 0.0305 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 171/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 6.1411e-08 - acc: 1.0000\n",
      "Epoch 171: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 28ms/step - loss: 6.1411e-08 - acc: 1.0000 - val_loss: 0.0305 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 172/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 6.0769e-08 - acc: 1.0000\n",
      "Epoch 172: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 27ms/step - loss: 5.9700e-08 - acc: 1.0000 - val_loss: 0.0310 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 173/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 5.8102e-08 - acc: 1.0000\n",
      "Epoch 173: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 5.8102e-08 - acc: 1.0000 - val_loss: 0.0312 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 174/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 5.7147e-08 - acc: 1.0000\n",
      "Epoch 174: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 26ms/step - loss: 5.6581e-08 - acc: 1.0000 - val_loss: 0.0310 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 175/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 5.4794e-08 - acc: 1.0000\n",
      "Epoch 175: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 29ms/step - loss: 5.4794e-08 - acc: 1.0000 - val_loss: 0.0311 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 176/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 5.3767e-08 - acc: 1.0000\n",
      "Epoch 176: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 27ms/step - loss: 5.3235e-08 - acc: 1.0000 - val_loss: 0.0308 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 177/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 5.1866e-08 - acc: 1.0000\n",
      "Epoch 177: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 27ms/step - loss: 5.1866e-08 - acc: 1.0000 - val_loss: 0.0309 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 178/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 4.9399e-08 - acc: 1.0000\n",
      "Epoch 178: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 5.0345e-08 - acc: 1.0000 - val_loss: 0.0314 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 179/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 4.9274e-08 - acc: 1.0000\n",
      "Epoch 179: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 4.8862e-08 - acc: 1.0000 - val_loss: 0.0320 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 180/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 4.8273e-08 - acc: 1.0000\n",
      "Epoch 180: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 26ms/step - loss: 4.7341e-08 - acc: 1.0000 - val_loss: 0.0310 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 181/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 4.5363e-08 - acc: 1.0000\n",
      "Epoch 181: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 29ms/step - loss: 4.5744e-08 - acc: 1.0000 - val_loss: 0.0315 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 182/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 4.4975e-08 - acc: 1.0000\n",
      "Epoch 182: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 4.4185e-08 - acc: 1.0000 - val_loss: 0.0309 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 183/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 4.3190e-08 - acc: 1.0000\n",
      "Epoch 183: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 28ms/step - loss: 4.2588e-08 - acc: 1.0000 - val_loss: 0.0315 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 184/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 4.0901e-08 - acc: 1.0000\n",
      "Epoch 184: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 4.1333e-08 - acc: 1.0000 - val_loss: 0.0310 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 185/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 3.9698e-08 - acc: 1.0000\n",
      "Epoch 185: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 3.9698e-08 - acc: 1.0000 - val_loss: 0.0320 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 186/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 3.9271e-08 - acc: 1.0000\n",
      "Epoch 186: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 3.8558e-08 - acc: 1.0000 - val_loss: 0.0310 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 187/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 3.7151e-08 - acc: 1.0000\n",
      "Epoch 187: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 28ms/step - loss: 3.7151e-08 - acc: 1.0000 - val_loss: 0.0313 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 188/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.5909e-08 - acc: 1.0000\n",
      "Epoch 188: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 28ms/step - loss: 3.5896e-08 - acc: 1.0000 - val_loss: 0.0321 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 189/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 3.4565e-08 - acc: 1.0000\n",
      "Epoch 189: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 32ms/step - loss: 3.4565e-08 - acc: 1.0000 - val_loss: 0.0315 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 190/200\n",
      "96/98 [============================>.] - ETA: 0s - loss: 3.4071e-08 - acc: 1.0000\n",
      "Epoch 190: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 30ms/step - loss: 3.3386e-08 - acc: 1.0000 - val_loss: 0.0317 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 191/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 3.2414e-08 - acc: 1.0000\n",
      "Epoch 191: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 30ms/step - loss: 3.2131e-08 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 192/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 3.0915e-08 - acc: 1.0000\n",
      "Epoch 192: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 26ms/step - loss: 3.0915e-08 - acc: 1.0000 - val_loss: 0.0325 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 193/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.9764e-08 - acc: 1.0000\n",
      "Epoch 193: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 2.9470e-08 - acc: 1.0000 - val_loss: 0.0316 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 194/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.8367e-08 - acc: 1.0000\n",
      "Epoch 194: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 2.8367e-08 - acc: 1.0000 - val_loss: 0.0318 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 195/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.7652e-08 - acc: 1.0000\n",
      "Epoch 195: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 2.7378e-08 - acc: 1.0000 - val_loss: 0.0317 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 196/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.6461e-08 - acc: 1.0000\n",
      "Epoch 196: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 2.6237e-08 - acc: 1.0000 - val_loss: 0.0312 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 197/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.5347e-08 - acc: 1.0000\n",
      "Epoch 197: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 2.5097e-08 - acc: 1.0000 - val_loss: 0.0326 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 198/200\n",
      "98/98 [==============================] - ETA: 0s - loss: 2.4260e-08 - acc: 1.0000\n",
      "Epoch 198: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 2.4260e-08 - acc: 1.0000 - val_loss: 0.0325 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 199/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.2429e-08 - acc: 1.0000\n",
      "Epoch 199: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 30ms/step - loss: 2.3119e-08 - acc: 1.0000 - val_loss: 0.0317 - val_acc: 0.9971 - lr: 1.2500e-04\n",
      "Epoch 200/200\n",
      "97/98 [============================>.] - ETA: 0s - loss: 2.2006e-08 - acc: 1.0000\n",
      "Epoch 200: val_acc did not improve from 1.00000\n",
      "98/98 [==============================] - 3s 28ms/step - loss: 2.2207e-08 - acc: 1.0000 - val_loss: 0.0327 - val_acc: 0.9971 - lr: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=200,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('models/model.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[263,   0],\n",
       "        [  0,  86]],\n",
       "\n",
       "       [[268,   0],\n",
       "        [  0,  81]],\n",
       "\n",
       "       [[247,   0],\n",
       "        [  0, 102]],\n",
       "\n",
       "       [[269,   0],\n",
       "        [  0,  80]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('models/model.h5')\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
